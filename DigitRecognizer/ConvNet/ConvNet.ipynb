{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawData = pd.read_csv(\"../input/train.csv\").values\n",
    "rawSubmission = pd.read_csv(\"../input/test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#suffle dataset\n",
    "np.random.shuffle(rawData)\n",
    "\n",
    "trainSamples = rawData.shape[0] # amount of samples in training set\n",
    "testSamples = rawSubmission.shape[0] # amount of samples in test set\n",
    "imgSize = 28 # image size (both width and height)\n",
    "colorChannels = 1 # images are grayscale\n",
    "\n",
    "# reshape and normalize\n",
    "X = rawData[:, 1:].astype(\"float32\").reshape( (trainSamples, imgSize, imgSize, colorChannels) ) / 255.0\n",
    "testX = rawSubmission.astype(\"float32\").reshape( (testSamples, imgSize, imgSize, colorChannels) ) / 255.0\n",
    "\n",
    "Y = np_utils.to_categorical( rawData[:,0].astype(\"int\") )\n",
    "\n",
    "numClasses = Y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will use 3 conv layers with 32 filters with size 5x5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, input_shape=(imgSize, imgSize, colorChannels), \n",
    "                        border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(numClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_66 (Convolution2D) (None, 28, 28, 32)    832         convolution2d_input_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)             (None, 28, 28, 32)    0           convolution2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_67 (Convolution2D) (None, 28, 28, 32)    25632       dropout_66[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_42 (MaxPooling2D)   (None, 14, 14, 32)    0           convolution2d_67[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)             (None, 14, 14, 32)    0           maxpooling2d_42[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_68 (Convolution2D) (None, 14, 14, 32)    25632       dropout_67[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_43 (MaxPooling2D)   (None, 7, 7, 32)      0           convolution2d_68[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 1568)          0           maxpooling2d_43[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_49 (Dense)                 (None, 512)           803328      flatten_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)             (None, 512)           0           dense_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                 (None, 10)            5130        dropout_68[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 860554\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# stop training if val_loss stop decreasing after 2 epoch\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/25\n",
      "31500/31500 [==============================] - 389s - loss: 0.3120 - acc: 0.8974 - val_loss: 0.0703 - val_acc: 0.9771\n",
      "Epoch 2/25\n",
      "31500/31500 [==============================] - 384s - loss: 0.0756 - acc: 0.9760 - val_loss: 0.0510 - val_acc: 0.9835\n",
      "Epoch 3/25\n",
      "31500/31500 [==============================] - 382s - loss: 0.0550 - acc: 0.9829 - val_loss: 0.0442 - val_acc: 0.9862\n",
      "Epoch 4/25\n",
      "31500/31500 [==============================] - 370s - loss: 0.0428 - acc: 0.9862 - val_loss: 0.0398 - val_acc: 0.9890\n",
      "Epoch 5/25\n",
      "31500/31500 [==============================] - 355s - loss: 0.0353 - acc: 0.9889 - val_loss: 0.0384 - val_acc: 0.9890\n",
      "Epoch 6/25\n",
      "31500/31500 [==============================] - 374s - loss: 0.0285 - acc: 0.9908 - val_loss: 0.0377 - val_acc: 0.9891\n",
      "Epoch 7/25\n",
      "31500/31500 [==============================] - 379s - loss: 0.0253 - acc: 0.9920 - val_loss: 0.0369 - val_acc: 0.9896\n",
      "Epoch 8/25\n",
      "31500/31500 [==============================] - 378s - loss: 0.0222 - acc: 0.9926 - val_loss: 0.0366 - val_acc: 0.9900\n",
      "Epoch 9/25\n",
      "31500/31500 [==============================] - 377s - loss: 0.0209 - acc: 0.9937 - val_loss: 0.0338 - val_acc: 0.9909\n",
      "Epoch 10/25\n",
      "31500/31500 [==============================] - 378s - loss: 0.0191 - acc: 0.9939 - val_loss: 0.0331 - val_acc: 0.9910\n",
      "Epoch 11/25\n",
      "31500/31500 [==============================] - 379s - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0341 - val_acc: 0.9899\n",
      "Epoch 12/25\n",
      "31500/31500 [==============================] - 380s - loss: 0.0167 - acc: 0.9951 - val_loss: 0.0336 - val_acc: 0.9911\n",
      "Epoch 13/25\n",
      "31500/31500 [==============================] - 384s - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0334 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22448c1cc0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation_split = 0.25 - split oyr dataset: train on 75% of samples and validate on 25%\n",
    "model.fit(X, Y, validation_split = 0.25, nb_epoch=epochs, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionaly save model to .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('convnet_9910.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 110s   \n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = np.column_stack( (np.arange(1, predicted.shape[0]+1), predicted) )\n",
    "np.savetxt('convnet_v1.csv', submission, delimiter=',', header = 'ImageId,Label', fmt=\"%d\", comments='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
